{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Conv2D,MaxPool2D,GlobalMaxPool2D,Flatten,Dense,Dropout,Input,Lambda\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "import keras.backend as K\n",
    "import librosa\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram(clip,sample_rate,save_path):\n",
    "  plt.interactive(False)\n",
    "  fig=plt.figure(figsize=[0.72,0.72])\n",
    "  ax=fig.add_subplot(111)\n",
    "  ax.axes.get_xaxis().set_visible(False)\n",
    "  ax.axes.get_yaxis().set_visible(False)\n",
    "  ax.set_frame_on(False)\n",
    "  S=librosa.feature.melspectrogram(y=clip,sr=sample_rate)\n",
    "  librosa.display.specshow(librosa.power_to_db(S,ref=np.max))\n",
    "  fig.savefig(save_path,dpi=400,bbox_inches='tight',pad_inches=0)\n",
    "  plt.close()\n",
    "  fig.clf()\n",
    "  plt.close(fig)\n",
    "  plt.close('all')\n",
    "  del save_path,clip,sample_rate,fig,ax,S\n",
    "\n",
    "def get_encoder(input_size):\n",
    "  model=Sequential()\n",
    "  model.add(Conv2D(32,(3,3),input_shape=(150,150,3),activation='relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "  model.add(MaxPool2D(2,2))\n",
    "  model.add(Dropout(0.5))\n",
    "\n",
    "  model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "  model.add(MaxPool2D(2,2))\n",
    "  model.add(Dropout(0.5))\n",
    "\n",
    "#   model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "#   model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "#   model.add(MaxPool2D(2,2))\n",
    "#   model.add(Dropout(0.5))\n",
    "\n",
    "  model.add(GlobalMaxPool2D())\n",
    "\n",
    "  return model\n",
    "\n",
    "def get_siamese_network(encoder,input_size):\n",
    "  input1=Input(input_size)\n",
    "  input2=Input(input_size)\n",
    "\n",
    "  encoder_l=encoder(input1)\n",
    "  encoder_r=encoder(input2)\n",
    "  \n",
    "  L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "  L1_distance = L1_layer([encoder_l, encoder_r])\n",
    "\n",
    "  output=Dense(1,activation='sigmoid')(L1_distance)\n",
    "  siam_model=Model(inputs=[input1,input2],outputs=output)\n",
    "  return siam_model\n",
    "\n",
    "encoder=get_encoder((150,150,3))\n",
    "siamese_net=get_siamese_network(encoder,(150,150,3))\n",
    "siamese_net.compile(loss='binary_crossentropy',optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_list=os.listdir('D:/Songs/')\n",
    "songs_list.remove('pvt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the songs,divide them into 10s segment,create spectrogram of them\n",
    "\n",
    "charsets=string.ascii_letters\n",
    "\n",
    "def get_random_name():\n",
    "    name=''.join([random.choice(charsets) for _ in range(20)])\n",
    "    name=name+str(np.random.randint(0,1000))\n",
    "    return name\n",
    "\n",
    "for song in songs_list:\n",
    "    print(song)\n",
    "    songfile,sr=librosa.load('D:/Songs/'+song)\n",
    "    duration=librosa.get_duration(songfile,sr)\n",
    "    prev=0\n",
    "    for i in range(1,int((duration//10)+1)):\n",
    "        if i==int((duration//10)):\n",
    "            \"\"\"Since we are dividing the song in 10s segment there might be case that after taking 10\n",
    "            fragments also few more seconds are left so in this case extra becomes extra=extra+(10-extra) \n",
    "            from the previous segment.\"\"\"\n",
    "            extra=int((int(duration)/10-int(int(duration)/10))*10) \n",
    "            st=(sr*i*10)-(10-extra)\n",
    "            end=st+10\n",
    "            songfrag=np.copy(songfile[st:end])\n",
    "        else:\n",
    "            songfrag=np.copy(songfile[prev:(sr*i*10)])\n",
    "        specname=get_random_name()\n",
    "        create_spectrogram(songfrag,sr,'./Spectrograms/'+specname+'.png')\n",
    "        prev=sr*i*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def different_label_index(X):\n",
    "    idx1=0\n",
    "    idx2=0\n",
    "    while idx1==idx2:\n",
    "        idx1=np.random.randint(0,len(X))\n",
    "        idx2=np.random.randint(0,len(X))\n",
    "    return idx1,idx2\n",
    "def load_img(path):\n",
    "  img=cv2.imread(path)\n",
    "  img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "  img=cv2.resize(img,(150,150))\n",
    "  return img\n",
    "\n",
    "\n",
    "def batch_generator(X,batch_size):\n",
    "  while True:\n",
    "    data=[np.zeros((batch_size,150,150,3)) for i in range(2)]\n",
    "    tar=[np.zeros(batch_size,)]\n",
    "\n",
    "    #Generating same pairs.\n",
    "    for i in range(0,batch_size//2):\n",
    "      idx1=np.random.randint(0,len(X))\n",
    "      img1=load_img(X[idx1])\n",
    "      img1=img1/255\n",
    "\n",
    "      data[0][i,:,:,:]=img1\n",
    "      data[1][i,:,:,:]=img1\n",
    "      tar[0][i]=1\n",
    "\n",
    "    #Generating different pairs.\n",
    "    for k in range(batch_size//2,batch_size):\n",
    "      idx1,idx2=different_label_index(X)\n",
    "      img1=load_img(X[idx1])\n",
    "      img1=img1/255\n",
    "      img2=load_img(X[idx2])\n",
    "      img2=img2/255\n",
    "\n",
    "      data[0][k,:,:,:]=img1\n",
    "      data[1][k,:,:,:]=img2\n",
    "      tar[0][k]=0\n",
    "    np.delete(data[0],np.where(~data[0].any(axis=1))[0], axis=0)\n",
    "    np.delete(data[1],np.where(~data[1].any(axis=1))[0], axis=0)\n",
    "    yield data,tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=10\n",
    "specfilelist=os.listdir('./Spectrograms/')\n",
    "specfilelist=['./Spectrograms/'+filename for filename in specfilelist]\n",
    "specfilelist=shuffle(specfilelist)\n",
    "\n",
    "X_train=specfilelist[0:int(0.75*len(specfilelist))]\n",
    "X_test=specfilelist[int(0.75*len(specfilelist)):]\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, min_delta=0.0001) \n",
    "mc = ModelCheckpoint('SpeakerID_best.hdf5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "history=siamese_net.fit_generator(batch_generator(X_train,batch_size),steps_per_epoch=len(X_train)//batch_size,epochs=50,validation_data=batch_generator(X_test,batch_size),\n",
    "                            validation_steps=len(X_test)//batch_size,callbacks=[es,mc],shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model=load_model('SpeakerID_best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_two(arr1,arr2):\n",
    "    create_spectrogram(arr1,22050,'1.png')\n",
    "    create_spectrogram(arr2,22050,'2.png')\n",
    "    data=[np.zeros((1,150,150,3)) for i in range(2)]\n",
    "    img1=load_img('1.png')\n",
    "    img2=load_img('2.png')\n",
    "    data[0][0,:,:,:]=img1\n",
    "    data[1][0,:,:,:]=img2\n",
    "    print(model.predict(data))\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song,sr=librosa.load('Songs/'+'14 Tell Me Why.m4a')\n",
    "songs_part1=np.copy(song[0:220500])\n",
    "songs_part2=np.copy(song[220500:441000])\n",
    "songs_part3=np.copy(song[441000:661500])\n",
    "\n",
    "match_two(songs_part1,songs_part1)\n",
    "match_two(songs_part1,songs_part2)\n",
    "match_two(songs_part1,songs_part3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_test,sr=librosa.load('test.m4a')\n",
    "songs_test_prt=np.copy(song_test[0:220500])\n",
    "match_two(songs_part1,songs_test_prt)\n",
    "match_two(songs_part2,songs_test_prt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow15",
   "language": "python",
   "name": "tensorflow15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
